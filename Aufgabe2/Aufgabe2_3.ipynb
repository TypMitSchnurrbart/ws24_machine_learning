{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-13T21:39:27.985206700Z",
     "start_time": "2023-11-13T21:39:27.587203600Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verzeichnis gefunden.\n"
     ]
    }
   ],
   "source": [
    "########### 2a Personen mit >70 Bildern #############\n",
    "import os, tarfile\n",
    "from urllib.request import urlretrieve\n",
    "if not os.path.isfile('lfw-funneled.tgz'):\n",
    "    print(\"Downloading\")\n",
    "    urlretrieve('http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz',filename = 'lfw-funneled.tgz')\n",
    "    \n",
    "# Pfad zur heruntergeladenen tgz-Datei\n",
    "tgz_file = 'lfw-funneled.tgz'\n",
    "\n",
    "# Zielverzeichnis für die Extraktion\n",
    "extracted_directory = 'lfw_funneled'\n",
    "\n",
    "# Extrahiere den Datensatz aus der tgz-Datei\n",
    "if not os.path.exists(extracted_directory):\n",
    "    with tarfile.open(tgz_file, 'r:gz') as tar:\n",
    "        print(\"Extracting...\")\n",
    "        tar.extractall(os.getcwd())\n",
    "else: \n",
    "    print(\"Verzeichnis gefunden.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T21:39:27.987202100Z",
     "start_time": "2023-11-13T21:39:27.605204200Z"
    }
   },
   "id": "503f7ae1a175ae8a"
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ariel_Sharon: 77 Bilder\n",
      "Colin_Powell: 236 Bilder\n",
      "Donald_Rumsfeld: 121 Bilder\n",
      "George_W_Bush: 530 Bilder\n",
      "Gerhard_Schroeder: 109 Bilder\n",
      "Hugo_Chavez: 71 Bilder\n",
      "Tony_Blair: 144 Bilder\n"
     ]
    }
   ],
   "source": [
    "# Funktion zum Durchsuchen des Verzeichnisses und Ermitteln der Personen mit mindestens 70 Bildern\n",
    "def find_persons_with_min_images(dataset_directory, min_images=70):\n",
    "    persons = {}\n",
    "    \n",
    "    for root, dirs, files in os.walk(dataset_directory):\n",
    "        if len(files) >= min_images:\n",
    "            person_name = os.path.basename(root)\n",
    "            persons[person_name] = len(files)\n",
    "\n",
    "    return {k: v for k, v in persons.items() if v >= min_images}\n",
    "\n",
    "persons = find_persons_with_min_images(extracted_directory, min_images=70)\n",
    "\n",
    "# Ausgabe der gefundenen Personen\n",
    "for person, num_images in persons.items():\n",
    "    print(f'{person}: {num_images} Bilder')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T21:39:29.863770200Z",
     "start_time": "2023-11-13T21:39:27.616205300Z"
    }
   },
   "id": "d9d8cde84f602983"
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Trainingsbilder:  1288\n"
     ]
    }
   ],
   "source": [
    "########### 2b #############\n",
    "from skimage import io, transform\n",
    "lfw_path = os.path.join(os.getcwd(), extracted_directory)\n",
    "    \n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for person in persons.keys():\n",
    "    person_folder = os.path.join(lfw_path, person)\n",
    "    \n",
    "    for i, img_name in enumerate(os.listdir(person_folder)):\n",
    "        img_path = os.path.join(person_folder, img_name)\n",
    "        img = io.imread(img_path, as_gray=True)\n",
    "        \n",
    "        # Bildmitte berechnen\n",
    "        height, width = img.shape[:2]\n",
    "        center_x, center_y = width // 2, height // 2\n",
    "        \n",
    "        # Ausschnittsgröße festlegen\n",
    "        crop_size = 96\n",
    "        \n",
    "        # Berechne den Ausschnitt\n",
    "        crop_x1 = center_x - (crop_size // 2)\n",
    "        crop_x2 = center_x + (crop_size // 2)\n",
    "        crop_y1 = center_y - (crop_size // 2)\n",
    "        crop_y2 = center_y + (crop_size // 2)\n",
    "        \n",
    "        # Den Ausschnitt ausschneiden\n",
    "        img = img[crop_y1:crop_y2, crop_x1:crop_x2]\n",
    "        img = transform.resize(img, (32, 32))\n",
    "        img = img.flatten()\n",
    "        \n",
    "        # Save the test picture\n",
    "        if person == \"George_W_Bush\":\n",
    "            labels.append(1.0)\n",
    "        else:\n",
    "            labels.append(-1.0)\n",
    "            \n",
    "        images.append(img)\n",
    "\n",
    "print(\"Anzahl Trainingsbilder: \", len(images))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T21:39:34.997938800Z",
     "start_time": "2023-11-13T21:39:29.866768Z"
    }
   },
   "id": "db6689ea8461a9c3"
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "772 + 516 = 1288 <=> 1288\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(images)\n",
    "y = np.array(labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, shuffle=True)\n",
    "\n",
    "print(len(X_train), \"+\", len(X_test), \"=\", len(X_train) + len(X_test), \"<=>\", len(images))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T21:39:35.127190900Z",
     "start_time": "2023-11-13T21:39:35.000938300Z"
    }
   },
   "id": "3e0c672949cf7b9d"
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Design Matrix:  (772, 1024)\n"
     ]
    },
    {
     "data": {
      "text/plain": "       0         1         2         3         4         5         6     \\\n0  0.109214  0.200172  0.381743  0.489545  0.536460  0.560711  0.575888   \n1  0.582930  0.688128  0.779734  0.805643  0.805638  0.795169  0.770843   \n2  0.125745  0.305503  0.379340  0.513460  0.643709  0.704966  0.771127   \n3  0.459664  0.465377  0.540511  0.612394  0.684091  0.677095  0.689201   \n4  0.518882  0.472868  0.432625  0.458356  0.485482  0.514903  0.536523   \n\n       7         8         9     ...      1014      1015      1016      1017  \\\n0  0.600522  0.608648  0.611475  ...  0.522324  0.528886  0.553327  0.530423   \n1  0.751230  0.744945  0.747546  ...  0.567832  0.579502  0.605916  0.639460   \n2  0.809545  0.822585  0.779196  ...  0.389338  0.349493  0.341828  0.353841   \n3  0.725177  0.770056  0.800829  ...  0.389256  0.397796  0.435900  0.434809   \n4  0.544992  0.569523  0.588650  ...  0.469462  0.484506  0.508066  0.512761   \n\n       1018      1019      1020      1021      1022      1023  \n0  0.494960  0.476641  0.472823  0.410509  0.344780  0.373695  \n1  0.619121  0.595679  0.592407  0.503467  0.400279  0.313158  \n2  0.349461  0.297810  0.246619  0.267566  0.240269  0.218483  \n3  0.471418  0.508190  0.506922  0.462020  0.405478  0.360806  \n4  0.510656  0.490752  0.479971  0.429558  0.379284  0.461528  \n\n[5 rows x 1024 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>1014</th>\n      <th>1015</th>\n      <th>1016</th>\n      <th>1017</th>\n      <th>1018</th>\n      <th>1019</th>\n      <th>1020</th>\n      <th>1021</th>\n      <th>1022</th>\n      <th>1023</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.109214</td>\n      <td>0.200172</td>\n      <td>0.381743</td>\n      <td>0.489545</td>\n      <td>0.536460</td>\n      <td>0.560711</td>\n      <td>0.575888</td>\n      <td>0.600522</td>\n      <td>0.608648</td>\n      <td>0.611475</td>\n      <td>...</td>\n      <td>0.522324</td>\n      <td>0.528886</td>\n      <td>0.553327</td>\n      <td>0.530423</td>\n      <td>0.494960</td>\n      <td>0.476641</td>\n      <td>0.472823</td>\n      <td>0.410509</td>\n      <td>0.344780</td>\n      <td>0.373695</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.582930</td>\n      <td>0.688128</td>\n      <td>0.779734</td>\n      <td>0.805643</td>\n      <td>0.805638</td>\n      <td>0.795169</td>\n      <td>0.770843</td>\n      <td>0.751230</td>\n      <td>0.744945</td>\n      <td>0.747546</td>\n      <td>...</td>\n      <td>0.567832</td>\n      <td>0.579502</td>\n      <td>0.605916</td>\n      <td>0.639460</td>\n      <td>0.619121</td>\n      <td>0.595679</td>\n      <td>0.592407</td>\n      <td>0.503467</td>\n      <td>0.400279</td>\n      <td>0.313158</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.125745</td>\n      <td>0.305503</td>\n      <td>0.379340</td>\n      <td>0.513460</td>\n      <td>0.643709</td>\n      <td>0.704966</td>\n      <td>0.771127</td>\n      <td>0.809545</td>\n      <td>0.822585</td>\n      <td>0.779196</td>\n      <td>...</td>\n      <td>0.389338</td>\n      <td>0.349493</td>\n      <td>0.341828</td>\n      <td>0.353841</td>\n      <td>0.349461</td>\n      <td>0.297810</td>\n      <td>0.246619</td>\n      <td>0.267566</td>\n      <td>0.240269</td>\n      <td>0.218483</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.459664</td>\n      <td>0.465377</td>\n      <td>0.540511</td>\n      <td>0.612394</td>\n      <td>0.684091</td>\n      <td>0.677095</td>\n      <td>0.689201</td>\n      <td>0.725177</td>\n      <td>0.770056</td>\n      <td>0.800829</td>\n      <td>...</td>\n      <td>0.389256</td>\n      <td>0.397796</td>\n      <td>0.435900</td>\n      <td>0.434809</td>\n      <td>0.471418</td>\n      <td>0.508190</td>\n      <td>0.506922</td>\n      <td>0.462020</td>\n      <td>0.405478</td>\n      <td>0.360806</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.518882</td>\n      <td>0.472868</td>\n      <td>0.432625</td>\n      <td>0.458356</td>\n      <td>0.485482</td>\n      <td>0.514903</td>\n      <td>0.536523</td>\n      <td>0.544992</td>\n      <td>0.569523</td>\n      <td>0.588650</td>\n      <td>...</td>\n      <td>0.469462</td>\n      <td>0.484506</td>\n      <td>0.508066</td>\n      <td>0.512761</td>\n      <td>0.510656</td>\n      <td>0.490752</td>\n      <td>0.479971</td>\n      <td>0.429558</td>\n      <td>0.379284</td>\n      <td>0.461528</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1024 columns</p>\n</div>"
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train = pd.DataFrame(X_train)\n",
    "df_X_test = pd.DataFrame(X_test)\n",
    "df_y_train = pd.DataFrame(y_train)\n",
    "df_y_test = pd.DataFrame(y_test)\n",
    "\n",
    "print(\"Shape Design Matrix: \", df_X_train.shape)\n",
    "df_X_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T21:39:35.141193700Z",
     "start_time": "2023-11-13T21:39:35.028212200Z"
    }
   },
   "id": "b685fee973f3f5de"
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train PCA:\n",
      "\tEigenvectores shape:  (1024, 1024)\n",
      "\tEigenfaces shape:  (7, 1024)\n",
      "\tShape Train Scores:  (772, 7)\n",
      "\n",
      "Test PCA:\n",
      "\tEigenvectores shape:  (1024, 1024)\n",
      "\tEigenfaces shape:  (7, 1024)\n",
      "\tShape Test Scores:  (516, 7)\n"
     ]
    }
   ],
   "source": [
    "###### PCA\n",
    "def pca(matrix):\n",
    "    \n",
    "    # Zentrierung\n",
    "    matrix = (matrix - matrix.mean()) / matrix.std()\n",
    "    \n",
    "    # SVD\n",
    "    U, D, V = np.linalg.svd(matrix)\n",
    "    eigenvectors = V\n",
    "    print(\"\\tEigenvectores shape: \", eigenvectors.shape)\n",
    "    eigenfaces = eigenvectors[:7]\n",
    "    print(\"\\tEigenfaces shape: \", eigenfaces.shape)\n",
    "    \n",
    "    # Transform the data to the first 7 eigenfaces\n",
    "    scores = pd.DataFrame(np.matmul(matrix, eigenfaces.T))\n",
    "    return scores\n",
    "   \n",
    "# Transform the data to the first 7 eigenfaces\n",
    "print(\"Train PCA:\")\n",
    "design_matrix = df_X_train\n",
    "df_train_scores = pca(design_matrix)\n",
    "# print(train_scores.head())\n",
    "print(\"\\tShape Train Scores: \", df_train_scores.shape)\n",
    "\n",
    "print(\"\\nTest PCA:\")\n",
    "test_matrix = df_X_test\n",
    "df_test_scores = pca(test_matrix)\n",
    "# print(test_scores.head())\n",
    "print(\"\\tShape Test Scores: \", df_test_scores.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T21:39:35.663831300Z",
     "start_time": "2023-11-13T21:39:35.077193300Z"
    }
   },
   "id": "ff00b9c5f7b001d5"
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bush\n",
      "       mean    variance\n",
      "0  0.977832  280.662676\n",
      "1 -0.991274  194.361878\n",
      "2 -2.470285   51.723610\n",
      "3 -1.257515   55.267613\n",
      "4  0.856717   33.037959\n",
      "5 -1.963028   26.550370\n",
      "6  0.058712   25.862817\n",
      "\n",
      "Not Bush\n",
      "       mean    variance\n",
      "0 -0.681259  290.264574\n",
      "1  0.690624  144.782873\n",
      "2  1.721056   64.264975\n",
      "3  0.876115   52.193841\n",
      "4 -0.596878   30.789435\n",
      "5  1.367648   29.750331\n",
      "6 -0.040905   24.598042\n"
     ]
    }
   ],
   "source": [
    "### Bayes Classificator\n",
    "bush_stats = {\n",
    "    \"mean\" : [],\n",
    "    \"variance\" : []\n",
    "}\n",
    "\n",
    "not_bush_stats = {\n",
    "    \"mean\" : [],\n",
    "    \"variance\" : []\n",
    "}\n",
    "\n",
    "bush_scores = df_train_scores[df_y_train.iloc[:, 0] == 1.0]\n",
    "not_bush_scores = df_train_scores[df_y_train.iloc[:,0] == -1.0]\n",
    "\n",
    "for col in bush_scores:\n",
    "    bush_stats[\"mean\"].append(bush_scores[col].mean())\n",
    "    bush_stats[\"variance\"].append(bush_scores[col].var())\n",
    "\n",
    "for col in not_bush_scores:\n",
    "    not_bush_stats[\"mean\"].append(not_bush_scores[col].mean())\n",
    "    not_bush_stats[\"variance\"].append(not_bush_scores[col].var())\n",
    "\n",
    "bush_stats = pd.DataFrame(bush_stats)\n",
    "not_bush_stats = pd.DataFrame(not_bush_stats)\n",
    "print(\"Bush\")\n",
    "print(bush_stats)\n",
    "print(\"\\nNot Bush\")\n",
    "print(not_bush_stats)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T21:39:35.720830400Z",
     "start_time": "2023-11-13T21:39:35.664830700Z"
    }
   },
   "id": "6644cf4e6c5804f4"
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [],
   "source": [
    "# Compute the A-Priori of train daata\n",
    "prior_p_is_bush = df_y_train.value_counts().get(1.0, 0) / len(df_y_train)\n",
    "prior_p_not_bush = 1.0 - prior_p_is_bush"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T21:39:35.720830400Z",
     "start_time": "2023-11-13T21:39:35.690831300Z"
    }
   },
   "id": "38eead1e0de0a040"
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def predict_with_bayes_classificator(scores):\n",
    "    # Calculate the Gaussian probability values for each feature and class\n",
    "    y_pred = []\n",
    "    \n",
    "    for i, score in scores.iterrows():\n",
    "        likehoods = {\n",
    "            \"P_bush\" : [],\n",
    "            \"P_not\" : []\n",
    "        }\n",
    "        \n",
    "        for j, value in enumerate(score.values):\n",
    "    \n",
    "            mean = bush_stats[\"mean\"][j]\n",
    "            not_mean = not_bush_stats[\"mean\"][j]\n",
    "    \n",
    "            var = bush_stats[\"variance\"][j]\n",
    "            not_var = not_bush_stats[\"variance\"][j]\n",
    "    \n",
    "            likehoods[\"P_not\"].append((1 / (math.sqrt(2 * math.pi * not_var))) * math.exp(-(value - not_mean)**2 / (2 * not_var)))\n",
    "            likehoods[\"P_bush\"].append((1 / (math.sqrt(2 * math.pi * var))) * math.exp(-(value - mean)**2 / (2 * var)))\n",
    "        \n",
    "        # Now we got the pdfs P(x | c), probability of feature x under class c\n",
    "        # Now look at decision\n",
    "        post_p_bush = prior_p_is_bush\n",
    "        for like in likehoods[\"P_bush\"]:\n",
    "            post_p_bush *= like \n",
    "    \n",
    "        post_p_not_bush = prior_p_not_bush\n",
    "        for like in likehoods[\"P_not\"]:\n",
    "            post_p_not_bush *= like\n",
    "        \n",
    "        # Make the decision\n",
    "        if post_p_bush > post_p_not_bush:\n",
    "            y_pred.append(1.0)\n",
    "        else:\n",
    "            y_pred.append(-1.0)\n",
    "    \n",
    "    return y_pred\n",
    "                \n",
    "\n",
    "def evaluate_predictions(y_pred, y_true):\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    true_negative = 0\n",
    "    false_negative = 0\n",
    "    \n",
    "    for (y_p, y_t) in zip(y_pred, y_true):\n",
    "        if y_p == 1.0 and y_t == 1.0:\n",
    "                true_positive += 1\n",
    "        elif y_p == 1.0 and y_t == -1.0:\n",
    "            false_positive += 1\n",
    "        elif y_p == -1.0 and y_t == -1.0:\n",
    "            true_negative += 1\n",
    "        elif y_p == -1.0 and y_t == 1.0:\n",
    "            false_negative += 1\n",
    "    \n",
    "    n_data = len(y_pred)\n",
    "    print(f\"\"\"\n",
    "    Accurancy: \\t{np.sum(y_pred == y_true) / n_data}\n",
    "    True Positive:\\t{true_positive / n_data}\n",
    "    False Positive:\\t{false_positive / n_data}\n",
    "    True Negativ:\\t{true_negative / n_data}\n",
    "    False Negativ:\\t{false_negative / n_data}\n",
    "    \n",
    "    \"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T21:39:35.774642700Z",
     "start_time": "2023-11-13T21:39:35.707833900Z"
    }
   },
   "id": "67b69d25ba4b092d"
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking results on TRAINING data:\n",
      "\n",
      "    Accurancy: \t0.711139896373057\n",
      "    True Positive:\t0.22279792746113988\n",
      "    False Positive:\t0.10103626943005181\n",
      "    True Negativ:\t0.4883419689119171\n",
      "    False Negativ:\t0.1878238341968912\n",
      "    \n",
      "    \n",
      "\n",
      "Checking results on independent TEST data:\n",
      "\n",
      "    Accurancy: \t0.625968992248062\n",
      "    True Positive:\t0.19186046511627908\n",
      "    False Positive:\t0.15310077519379844\n",
      "    True Negativ:\t0.43410852713178294\n",
      "    False Negativ:\t0.22093023255813954\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Check for test data\n",
    "print(\"\\nChecking results on TRAINING data:\")\n",
    "y_train_pred = predict_with_bayes_classificator(df_train_scores)\n",
    "evaluate_predictions(y_train_pred, y_train)\n",
    "\n",
    "print(\"\\nChecking results on independent TEST data:\")\n",
    "y_test_pred = predict_with_bayes_classificator(df_test_scores)\n",
    "evaluate_predictions(y_test_pred, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T21:39:36.596874900Z",
     "start_time": "2023-11-13T21:39:35.733831300Z"
    }
   },
   "id": "17a53725ef0c7ce7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
