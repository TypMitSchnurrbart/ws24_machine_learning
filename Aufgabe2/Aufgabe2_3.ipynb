{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T23:28:25.445132600Z",
     "start_time": "2023-11-08T23:28:25.232135Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "503f7ae1a175ae8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T23:28:25.446133900Z",
     "start_time": "2023-11-08T23:28:25.259146100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verzeichnis gefunden.\n"
     ]
    }
   ],
   "source": [
    "########### 2a Personen mit >70 Bildern #############\n",
    "import os, tarfile\n",
    "from urllib.request import urlretrieve\n",
    "if not os.path.isfile('lfw-funneled.tgz'):\n",
    "    print(\"Downloading\")\n",
    "    urlretrieve('http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz',filename = 'lfw-funneled.tgz')\n",
    "    \n",
    "# Pfad zur heruntergeladenen tgz-Datei\n",
    "tgz_file = 'lfw-funneled.tgz'\n",
    "\n",
    "# Zielverzeichnis für die Extraktion\n",
    "extracted_directory = 'lfw_funneled'\n",
    "\n",
    "# Extrahiere den Datensatz aus der tgz-Datei\n",
    "if not os.path.exists(extracted_directory):\n",
    "    with tarfile.open(tgz_file, 'r:gz') as tar:\n",
    "        print(\"Extracting...\")\n",
    "        tar.extractall(os.getcwd())\n",
    "else: \n",
    "    print(\"Verzeichnis gefunden.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9d8cde84f602983",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T23:28:27.338134200Z",
     "start_time": "2023-11-08T23:28:25.274135900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ariel_Sharon: 77 Bilder\n",
      "Colin_Powell: 236 Bilder\n",
      "Donald_Rumsfeld: 121 Bilder\n",
      "George_W_Bush: 530 Bilder\n",
      "Gerhard_Schroeder: 109 Bilder\n",
      "Hugo_Chavez: 71 Bilder\n",
      "Tony_Blair: 144 Bilder\n"
     ]
    }
   ],
   "source": [
    "# Funktion zum Durchsuchen des Verzeichnisses und Ermitteln der Personen mit mindestens 70 Bildern\n",
    "person_dir_paths = []\n",
    "\n",
    "def find_persons_with_min_images(dataset_directory, min_images=70):\n",
    "    persons = {}\n",
    "    for root, dirs, files in os.walk(dataset_directory):\n",
    "        if len(files) >= min_images:\n",
    "            person_name = os.path.basename(root)\n",
    "            person_dir_paths.append(root)\n",
    "            persons[person_name] = len(files)\n",
    "\n",
    "    return {k: v for k, v in persons.items() if v >= min_images}\n",
    "\n",
    "\n",
    "persons = find_persons_with_min_images(extracted_directory, min_images=70)\n",
    "\n",
    "# Ausgabe der gefundenen Personen\n",
    "for person, num_images in persons.items():\n",
    "    print(f'{person}: {num_images} Bilder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e0c672949cf7b9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T23:28:31.832619Z",
     "start_time": "2023-11-08T23:28:31.785620200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitted into 516 test images and 772 training images.\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "image_paths = []\n",
    "image_name_indexes = []\n",
    "\n",
    "# Search in everys Person folder for images and append them to the lists\n",
    "for i, person_dir_path in enumerate(person_dir_paths):\n",
    "    files = sorted(listdir(person_dir_path))\n",
    "    for file in files:\n",
    "        image_name_indexes.append(i)\n",
    "        image_paths.append(f'{person_dir_path}/{file}')\n",
    "\n",
    "# Split the data into training and test data\n",
    "x_train_img_path, x_test_img_path, y_training_name_index, y_test_name_index = train_test_split(image_paths, image_name_indexes, test_size=0.4, random_state=0)\n",
    "\n",
    "print('Splitted into', len(x_test_img_path), 'test images and', len(x_train_img_path), 'training images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b685fee973f3f5de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T23:28:32.243619100Z",
     "start_time": "2023-11-08T23:28:31.813620700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Design Matrix:  (772, 1024)\n",
      "Shape Test Matrix:  (516, 1024)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500715</td>\n",
       "      <td>0.479520</td>\n",
       "      <td>0.687868</td>\n",
       "      <td>0.730689</td>\n",
       "      <td>0.747468</td>\n",
       "      <td>0.762788</td>\n",
       "      <td>0.730225</td>\n",
       "      <td>0.711743</td>\n",
       "      <td>0.713743</td>\n",
       "      <td>0.687237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.496647</td>\n",
       "      <td>0.485998</td>\n",
       "      <td>0.551722</td>\n",
       "      <td>0.622947</td>\n",
       "      <td>0.556574</td>\n",
       "      <td>0.477024</td>\n",
       "      <td>0.452327</td>\n",
       "      <td>0.431730</td>\n",
       "      <td>0.402049</td>\n",
       "      <td>0.410402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.510545</td>\n",
       "      <td>0.520284</td>\n",
       "      <td>0.636516</td>\n",
       "      <td>0.682492</td>\n",
       "      <td>0.711208</td>\n",
       "      <td>0.724303</td>\n",
       "      <td>0.729710</td>\n",
       "      <td>0.718356</td>\n",
       "      <td>0.743739</td>\n",
       "      <td>0.775675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361003</td>\n",
       "      <td>0.349891</td>\n",
       "      <td>0.328854</td>\n",
       "      <td>0.260119</td>\n",
       "      <td>0.263067</td>\n",
       "      <td>0.291812</td>\n",
       "      <td>0.313924</td>\n",
       "      <td>0.288129</td>\n",
       "      <td>0.239287</td>\n",
       "      <td>0.355265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.436124</td>\n",
       "      <td>0.488102</td>\n",
       "      <td>0.553063</td>\n",
       "      <td>0.598777</td>\n",
       "      <td>0.652305</td>\n",
       "      <td>0.691400</td>\n",
       "      <td>0.735770</td>\n",
       "      <td>0.784173</td>\n",
       "      <td>0.810917</td>\n",
       "      <td>0.813457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490018</td>\n",
       "      <td>0.401328</td>\n",
       "      <td>0.385687</td>\n",
       "      <td>0.373462</td>\n",
       "      <td>0.306952</td>\n",
       "      <td>0.303441</td>\n",
       "      <td>0.348612</td>\n",
       "      <td>0.364257</td>\n",
       "      <td>0.447986</td>\n",
       "      <td>0.681894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.350791</td>\n",
       "      <td>0.320254</td>\n",
       "      <td>0.411745</td>\n",
       "      <td>0.520783</td>\n",
       "      <td>0.566392</td>\n",
       "      <td>0.570777</td>\n",
       "      <td>0.593325</td>\n",
       "      <td>0.589648</td>\n",
       "      <td>0.604941</td>\n",
       "      <td>0.613002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350179</td>\n",
       "      <td>0.376242</td>\n",
       "      <td>0.317607</td>\n",
       "      <td>0.238791</td>\n",
       "      <td>0.171996</td>\n",
       "      <td>0.142533</td>\n",
       "      <td>0.143300</td>\n",
       "      <td>0.133569</td>\n",
       "      <td>0.132797</td>\n",
       "      <td>0.146890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.393305</td>\n",
       "      <td>0.395044</td>\n",
       "      <td>0.394139</td>\n",
       "      <td>0.424829</td>\n",
       "      <td>0.463218</td>\n",
       "      <td>0.511653</td>\n",
       "      <td>0.517516</td>\n",
       "      <td>0.497895</td>\n",
       "      <td>0.494390</td>\n",
       "      <td>0.566904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474702</td>\n",
       "      <td>0.490612</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>0.549045</td>\n",
       "      <td>0.578195</td>\n",
       "      <td>0.643133</td>\n",
       "      <td>0.611017</td>\n",
       "      <td>0.533875</td>\n",
       "      <td>0.316472</td>\n",
       "      <td>0.318593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.500715  0.479520  0.687868  0.730689  0.747468  0.762788  0.730225   \n",
       "1  0.510545  0.520284  0.636516  0.682492  0.711208  0.724303  0.729710   \n",
       "2  0.436124  0.488102  0.553063  0.598777  0.652305  0.691400  0.735770   \n",
       "3  0.350791  0.320254  0.411745  0.520783  0.566392  0.570777  0.593325   \n",
       "4  0.393305  0.395044  0.394139  0.424829  0.463218  0.511653  0.517516   \n",
       "\n",
       "       7         8         9     ...      1014      1015      1016      1017  \\\n",
       "0  0.711743  0.713743  0.687237  ...  0.496647  0.485998  0.551722  0.622947   \n",
       "1  0.718356  0.743739  0.775675  ...  0.361003  0.349891  0.328854  0.260119   \n",
       "2  0.784173  0.810917  0.813457  ...  0.490018  0.401328  0.385687  0.373462   \n",
       "3  0.589648  0.604941  0.613002  ...  0.350179  0.376242  0.317607  0.238791   \n",
       "4  0.497895  0.494390  0.566904  ...  0.474702  0.490612  0.563380  0.549045   \n",
       "\n",
       "       1018      1019      1020      1021      1022      1023  \n",
       "0  0.556574  0.477024  0.452327  0.431730  0.402049  0.410402  \n",
       "1  0.263067  0.291812  0.313924  0.288129  0.239287  0.355265  \n",
       "2  0.306952  0.303441  0.348612  0.364257  0.447986  0.681894  \n",
       "3  0.171996  0.142533  0.143300  0.133569  0.132797  0.146890  \n",
       "4  0.578195  0.643133  0.611017  0.533875  0.316472  0.318593  \n",
       "\n",
       "[5 rows x 1024 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2b\n",
    "from skimage import io, transform\n",
    "\n",
    "def transform_image(img):\n",
    "    # Bildmitte berechnen\n",
    "    height, width = img.shape[:2]\n",
    "    center_x, center_y = width // 2, height // 2\n",
    "    \n",
    "    # Ausschnittsgröße festlegen\n",
    "    crop_size = 96\n",
    "    \n",
    "    # Berechne den Ausschnitt\n",
    "    crop_x1 = center_x - (crop_size // 2)\n",
    "    crop_x2 = center_x + (crop_size // 2)\n",
    "    crop_y1 = center_y - (crop_size // 2)\n",
    "    crop_y2 = center_y + (crop_size // 2)\n",
    "    \n",
    "    # Den Ausschnitt ausschneiden\n",
    "    img = img[crop_y1:crop_y2, crop_x1:crop_x2]\n",
    "    img = transform.resize(img, (32, 32))\n",
    "    return img.flatten()\n",
    "\n",
    "x_train_images = []\n",
    "x_train_transformed = []\n",
    "\n",
    "for train_img_path in x_train_img_path:\n",
    "    img = io.imread(train_img_path, as_gray=True)\n",
    "    x_train_images.append(img)\n",
    "    img = transform_image(img)\n",
    "    x_train_transformed.append(img)\n",
    "\n",
    "design_matrix = np.array(x_train_transformed)\n",
    "\n",
    "x_test_images = []\n",
    "x_test_transformed = []\n",
    "\n",
    "for test_img_path in x_test_img_path:\n",
    "    img = io.imread(test_img_path, as_gray=True)\n",
    "    x_test_images.append(img)\n",
    "    img = transform_image(img)\n",
    "    x_test_transformed.append(img)\n",
    "\n",
    "test_matrix = np.array(x_test_transformed)\n",
    "\n",
    "df_train = pd.DataFrame(design_matrix)\n",
    "df_test = pd.DataFrame(test_matrix)\n",
    "\n",
    "print(\"Shape Design Matrix: \", design_matrix.shape)\n",
    "print(\"Shape Test Matrix: \", test_matrix.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff00b9c5f7b001d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T23:28:32.817560300Z",
     "start_time": "2023-11-08T23:28:32.265620600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvectores shape:  (1024, 1024)\n",
      "Eigenfaces shape:  (7, 1024)\n",
      "Eigenvectores shape:  (1024, 1024)\n",
      "Eigenfaces shape:  (7, 1024)\n"
     ]
    }
   ],
   "source": [
    "###### PCA 2c ######\n",
    "from sklearn import decomposition\n",
    "\n",
    "pca = decomposition.PCA(n_components=7, whiten=True)\n",
    "pca.fit(design_matrix)\n",
    "\n",
    "train_scores = pca.transform(design_matrix)\n",
    "test_scores = pca.transform(test_matrix)\n",
    "\n",
    "print(\"Shape Train Scores: \", train_scores.shape)\n",
    "###### PCA Diese Funktion funktioniert nicht, bzw kommen schlechtere ergebnisse ######\n",
    "# def pca(matrix):\n",
    "    \n",
    "#     # Zentrierung\n",
    "#     matrix = (matrix - matrix.mean()) / matrix.std()\n",
    "    \n",
    "#     # SVD\n",
    "#     U, D, V = np.linalg.svd(matrix)\n",
    "#     eigenvectors = V\n",
    "#     print(\"Eigenvectores shape: \", eigenvectors.shape)\n",
    "#     eigenfaces = eigenvectors[:7]\n",
    "#     print(\"Eigenfaces shape: \", eigenfaces.shape)\n",
    "    \n",
    "#     # Transform the data to the first 7 eigenfaces\n",
    "#     scores = pd.DataFrame(np.matmul(matrix, eigenfaces.T))\n",
    "#     return scores\n",
    "\n",
    "# train_scores = pca(design_matrix)\n",
    "# test_scores = pca(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_indexes(indexes):\n",
    "    # Because Bush is on the index 3 counting from 0 (4th person in List)\n",
    "    return [1 if index == 3 else -1 for index in indexes]\n",
    "\n",
    "def evaluate_prediction(prediction_indexes, observation_indexes):\n",
    "    prediction_labels = label_indexes(prediction_indexes)\n",
    "    observation_labels = label_indexes(observation_indexes)\n",
    "\n",
    "    true_positives = 0\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "    false_positives = 0\n",
    "    dates = 0\n",
    "\n",
    "    for i in range(len(prediction_indexes)):\n",
    "        dates += 1\n",
    "        prediction_label = prediction_labels[i]\n",
    "        observation_label = observation_labels[i]\n",
    "        if prediction_label == 1 and observation_label == 1:\n",
    "            true_positives += 1\n",
    "        if prediction_label == 1 and observation_label == -1:\n",
    "            false_positives += 1\n",
    "        if prediction_label == -1 and observation_label == -1:\n",
    "            true_negatives += 1\n",
    "        if prediction_label == -1 and observation_label == 1:\n",
    "            false_negatives += 1\n",
    "    \n",
    "\n",
    "\n",
    "    print('True Positives Rate:', round(100 * true_positives / dates), '%')\n",
    "    print('False Negatives Rate:', round(100 * false_negatives / dates), '%')\n",
    "    print('True Negatives Rate:', round(100 * true_negatives / dates), '%')\n",
    "    print('False Positives Rate:', round(100 * false_positives / dates), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data\n",
      "True Positives Rate: 11 %\n",
      "False Negatives Rate: 32 %\n",
      "True Negatives Rate: 47 %\n",
      "False Positives Rate: 10 %\n",
      "\n",
      "\n",
      "Training data\n",
      "True Positives Rate: 34 %\n",
      "False Negatives Rate: 6 %\n",
      "True Negatives Rate: 30 %\n",
      "False Positives Rate: 30 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Test data\n",
    "print('Test data')\n",
    "y_test_prediction = gnb.fit(train_scores, y_training_name_index).predict(test_scores)\n",
    "evaluate_prediction(y_test_prediction, y_test_name_index)\n",
    "print('\\n')\n",
    "\n",
    "# Training data\n",
    "print('Training data')\n",
    "y_train_prediction = gnb.fit(train_scores, y_training_name_index).predict(train_scores)\n",
    "evaluate_prediction(y_train_prediction, y_training_name_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data\n",
      "True Positives Rate: 39 %\n",
      "False Negatives Rate: 4 %\n",
      "True Negatives Rate: 20 %\n",
      "False Positives Rate: 37 %\n",
      "\n",
      "\n",
      "Training data\n",
      "True Positives Rate: 36 %\n",
      "False Negatives Rate: 4 %\n",
      "True Negatives Rate: 21 %\n",
      "False Positives Rate: 39 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3502: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3502: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# See: https://github.com/tigju/Naive-Bayes-Classifier-from-scratch/blob/main/naive_bayes.ipynb\n",
    "class NaiveBayesClassifier():\n",
    "\n",
    "    def calc_prior(self, features, target):\n",
    "        self.prior = (features.groupby(target).apply(lambda x: len(x)) / self.rows).to_numpy()\n",
    "        return self.prior\n",
    "\n",
    "    def calc_statistics(self, features, targets):\n",
    "        self.mean = features.groupby(targets).apply(np.mean).to_numpy()\n",
    "        self.var = features.groupby(targets).apply(np.var).to_numpy()\n",
    "        return self.mean, self.var\n",
    "\n",
    "    def gaussian_density(self, class_idx, x):\n",
    "        mean = self.mean[class_idx]\n",
    "        var = self.var[class_idx]\n",
    "        numerator = np.exp((-1/2)*((x-mean)**2) / (2 * var))\n",
    "        denominator = np.sqrt(2 * np.pi * var)\n",
    "        prob = numerator / denominator\n",
    "        return prob\n",
    "\n",
    "    def calc_posterior(self, x):\n",
    "        posteriors = []\n",
    "        for i in range(self.count):\n",
    "            prior = np.log(self.prior[i])\n",
    "            conditional = np.sum(np.log(self.gaussian_density(i, x)))\n",
    "            posterior = prior + conditional\n",
    "            posteriors.append(posterior)\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "\n",
    "    def fit(self, features, targets):\n",
    "        self.classes = np.unique(targets)\n",
    "        self.count = len(self.classes)\n",
    "        self.feature_nums = features.shape[1]\n",
    "        self.rows = features.shape[0]\n",
    "        self.calc_statistics(features, targets)\n",
    "        self.calc_prior(features, targets)\n",
    "\n",
    "    def predict(self, features):\n",
    "        preds = [self.calc_posterior(f) for f in features.to_numpy()]\n",
    "        return preds\n",
    "\n",
    "nbc = NaiveBayesClassifier()\n",
    "\n",
    "# Test data\n",
    "print('Test data')\n",
    "x_training_projections_df = pd.DataFrame(train_scores)\n",
    "y_training_name_index_df = pd.DataFrame(y_training_name_index)[0]\n",
    "x_test_projections_df = pd.DataFrame(test_scores)\n",
    "\n",
    "nbc.fit(x_training_projections_df, y_training_name_index_df)\n",
    "y_test_prediction = nbc.predict(x_test_projections_df)\n",
    "evaluate_prediction(y_test_prediction, y_test_name_index)\n",
    "print('\\n')\n",
    "\n",
    "# Training data\n",
    "print('Training data')\n",
    "x_training_projections_df = pd.DataFrame(train_scores)\n",
    "y_training_name_index_df = pd.DataFrame(y_training_name_index)[0]\n",
    "x_training_projections_df = pd.DataFrame(train_scores)\n",
    "\n",
    "nbc.fit(x_training_projections_df, y_training_name_index_df)\n",
    "y_training_prediction = nbc.predict(x_training_projections_df)\n",
    "evaluate_prediction(y_training_prediction, y_training_name_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
